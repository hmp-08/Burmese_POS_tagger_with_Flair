2023-11-16 09:20:26,519 ----------------------------------------------------------------------------------------------------
2023-11-16 09:20:26,521 Model: "SequenceTagger(
  (embeddings): CustomWordEmbeddings()
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=100, out_features=100, bias=True)
  (rnn): LSTM(100, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=18, bias=True)
  (loss_function): ViterbiLoss()
  (crf): CRF()
)"
2023-11-16 09:20:26,525 ----------------------------------------------------------------------------------------------------
2023-11-16 09:20:26,527 Corpus: 34989 train + 3888 dev + 4320 test sentences
2023-11-16 09:20:26,532 ----------------------------------------------------------------------------------------------------
2023-11-16 09:20:26,532 Train:  34989 sentences
2023-11-16 09:20:26,536         (train_with_dev=False, train_with_test=False)
2023-11-16 09:20:26,538 ----------------------------------------------------------------------------------------------------
2023-11-16 09:20:26,540 Training Params:
2023-11-16 09:20:26,542  - learning_rate: "0.1" 
2023-11-16 09:20:26,543  - mini_batch_size: "32"
2023-11-16 09:20:26,547  - max_epochs: "10"
2023-11-16 09:20:26,547  - shuffle: "True"
2023-11-16 09:20:26,548 ----------------------------------------------------------------------------------------------------
2023-11-16 09:20:26,549 Plugins:
2023-11-16 09:20:26,550  - AnnealOnPlateau | patience: '3', anneal_factor: '0.5', min_learning_rate: '0.0001'
2023-11-16 09:20:26,551 ----------------------------------------------------------------------------------------------------
2023-11-16 09:20:26,552 Final evaluation on model from best epoch (best-model.pt)
2023-11-16 09:20:26,553  - metric: "('micro avg', 'f1-score')"
2023-11-16 09:20:26,554 ----------------------------------------------------------------------------------------------------
2023-11-16 09:20:26,555 Computation:
2023-11-16 09:20:26,556  - compute on device: cuda:0
2023-11-16 09:20:26,557  - embedding storage: cpu
2023-11-16 09:20:26,558 ----------------------------------------------------------------------------------------------------
2023-11-16 09:20:26,559 Model training base path: "pos_tagger_w2v"
2023-11-16 09:20:26,560 ----------------------------------------------------------------------------------------------------
2023-11-16 09:20:26,562 ----------------------------------------------------------------------------------------------------
2023-11-16 09:20:36,179 epoch 1 - iter 109/1094 - loss 1.10930883 - time (sec): 9.62 - samples/sec: 4495.72 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:20:43,718 epoch 1 - iter 218/1094 - loss 0.87650244 - time (sec): 17.16 - samples/sec: 5038.02 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:20:51,584 epoch 1 - iter 327/1094 - loss 0.78056461 - time (sec): 25.02 - samples/sec: 5200.85 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:21:00,604 epoch 1 - iter 436/1094 - loss 0.71771525 - time (sec): 34.04 - samples/sec: 5114.46 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:21:10,823 epoch 1 - iter 545/1094 - loss 0.67560558 - time (sec): 44.26 - samples/sec: 4933.71 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:21:19,854 epoch 1 - iter 654/1094 - loss 0.64382540 - time (sec): 53.29 - samples/sec: 4932.62 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:21:27,437 epoch 1 - iter 763/1094 - loss 0.61968788 - time (sec): 60.87 - samples/sec: 5017.91 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:21:35,978 epoch 1 - iter 872/1094 - loss 0.60060386 - time (sec): 69.42 - samples/sec: 5026.77 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:21:42,941 epoch 1 - iter 981/1094 - loss 0.58351221 - time (sec): 76.38 - samples/sec: 5127.91 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:21:51,811 epoch 1 - iter 1090/1094 - loss 0.56853189 - time (sec): 85.25 - samples/sec: 5091.06 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:21:52,074 ----------------------------------------------------------------------------------------------------
2023-11-16 09:21:52,076 EPOCH 1 done: loss 0.5680 - lr: 0.100000
2023-11-16 09:22:02,973 DEV : loss 0.26060208678245544 - f1-score (micro avg)  0.9192
2023-11-16 09:22:03,238  - 0 epochs without improvement
2023-11-16 09:22:03,243 saving best model
2023-11-16 09:22:03,257 ----------------------------------------------------------------------------------------------------
2023-11-16 09:22:11,944 epoch 2 - iter 109/1094 - loss 0.42815902 - time (sec): 8.68 - samples/sec: 4972.78 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:22:19,491 epoch 2 - iter 218/1094 - loss 0.42612937 - time (sec): 16.23 - samples/sec: 5343.09 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:22:28,558 epoch 2 - iter 327/1094 - loss 0.42069821 - time (sec): 25.30 - samples/sec: 5119.10 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:22:35,848 epoch 2 - iter 436/1094 - loss 0.41786099 - time (sec): 32.59 - samples/sec: 5315.95 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:22:45,289 epoch 2 - iter 545/1094 - loss 0.41520458 - time (sec): 42.03 - samples/sec: 5156.42 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:22:52,614 epoch 2 - iter 654/1094 - loss 0.41249147 - time (sec): 49.35 - samples/sec: 5267.58 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:23:01,917 epoch 2 - iter 763/1094 - loss 0.40959196 - time (sec): 58.66 - samples/sec: 5174.74 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:23:09,451 epoch 2 - iter 872/1094 - loss 0.40851153 - time (sec): 66.19 - samples/sec: 5249.25 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:23:19,463 epoch 2 - iter 981/1094 - loss 0.40724518 - time (sec): 76.20 - samples/sec: 5129.60 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:23:26,768 epoch 2 - iter 1090/1094 - loss 0.40596212 - time (sec): 83.51 - samples/sec: 5198.14 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:23:27,059 ----------------------------------------------------------------------------------------------------
2023-11-16 09:23:27,061 EPOCH 2 done: loss 0.4059 - lr: 0.100000
2023-11-16 09:23:44,213 DEV : loss 0.22997337579727173 - f1-score (micro avg)  0.929
2023-11-16 09:23:44,370  - 0 epochs without improvement
2023-11-16 09:23:44,372 saving best model
2023-11-16 09:23:44,384 ----------------------------------------------------------------------------------------------------
2023-11-16 09:23:53,729 epoch 3 - iter 109/1094 - loss 0.38229644 - time (sec): 9.34 - samples/sec: 4555.44 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:24:01,330 epoch 3 - iter 218/1094 - loss 0.38675175 - time (sec): 16.94 - samples/sec: 5057.32 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:24:10,231 epoch 3 - iter 327/1094 - loss 0.38206419 - time (sec): 25.84 - samples/sec: 5012.62 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:24:18,666 epoch 3 - iter 436/1094 - loss 0.38285586 - time (sec): 34.28 - samples/sec: 5053.55 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:24:27,394 epoch 3 - iter 545/1094 - loss 0.38165484 - time (sec): 43.01 - samples/sec: 5052.47 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:24:36,052 epoch 3 - iter 654/1094 - loss 0.38034570 - time (sec): 51.67 - samples/sec: 5049.31 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:24:44,711 epoch 3 - iter 763/1094 - loss 0.37870314 - time (sec): 60.32 - samples/sec: 5047.94 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:24:53,129 epoch 3 - iter 872/1094 - loss 0.37657065 - time (sec): 68.74 - samples/sec: 5049.70 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:25:00,818 epoch 3 - iter 981/1094 - loss 0.37575600 - time (sec): 76.43 - samples/sec: 5107.64 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:25:09,760 epoch 3 - iter 1090/1094 - loss 0.37428999 - time (sec): 85.37 - samples/sec: 5085.84 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:25:09,960 ----------------------------------------------------------------------------------------------------
2023-11-16 09:25:09,961 EPOCH 3 done: loss 0.3743 - lr: 0.100000
2023-11-16 09:25:25,132 DEV : loss 0.21252262592315674 - f1-score (micro avg)  0.9349
2023-11-16 09:25:25,283  - 0 epochs without improvement
2023-11-16 09:25:25,285 saving best model
2023-11-16 09:25:25,295 ----------------------------------------------------------------------------------------------------
2023-11-16 09:25:32,480 epoch 4 - iter 109/1094 - loss 0.35279117 - time (sec): 7.18 - samples/sec: 5992.53 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:25:41,801 epoch 4 - iter 218/1094 - loss 0.35311795 - time (sec): 16.50 - samples/sec: 5221.74 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:25:49,325 epoch 4 - iter 327/1094 - loss 0.35470020 - time (sec): 24.03 - samples/sec: 5390.21 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:25:57,779 epoch 4 - iter 436/1094 - loss 0.35446758 - time (sec): 32.48 - samples/sec: 5314.28 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:26:05,531 epoch 4 - iter 545/1094 - loss 0.35549979 - time (sec): 40.23 - samples/sec: 5357.12 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:26:13,542 epoch 4 - iter 654/1094 - loss 0.35661193 - time (sec): 48.24 - samples/sec: 5365.74 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:26:25,713 epoch 4 - iter 763/1094 - loss 0.35656123 - time (sec): 60.42 - samples/sec: 5013.62 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:26:34,673 epoch 4 - iter 872/1094 - loss 0.35659039 - time (sec): 69.38 - samples/sec: 4995.23 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:26:43,311 epoch 4 - iter 981/1094 - loss 0.35615136 - time (sec): 78.01 - samples/sec: 5000.03 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:26:51,256 epoch 4 - iter 1090/1094 - loss 0.35601284 - time (sec): 85.96 - samples/sec: 5050.59 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:26:51,586 ----------------------------------------------------------------------------------------------------
2023-11-16 09:26:51,589 EPOCH 4 done: loss 0.3561 - lr: 0.100000
2023-11-16 09:27:07,521 DEV : loss 0.2078721523284912 - f1-score (micro avg)  0.9365
2023-11-16 09:27:07,778  - 0 epochs without improvement
2023-11-16 09:27:07,783 saving best model
2023-11-16 09:27:07,799 ----------------------------------------------------------------------------------------------------
2023-11-16 09:27:17,536 epoch 5 - iter 109/1094 - loss 0.35136357 - time (sec): 9.73 - samples/sec: 4540.26 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:27:24,505 epoch 5 - iter 218/1094 - loss 0.35462983 - time (sec): 16.70 - samples/sec: 5219.61 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:27:34,032 epoch 5 - iter 327/1094 - loss 0.35525298 - time (sec): 26.23 - samples/sec: 4964.96 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:27:41,052 epoch 5 - iter 436/1094 - loss 0.35326932 - time (sec): 33.25 - samples/sec: 5204.35 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:27:50,541 epoch 5 - iter 545/1094 - loss 0.35302567 - time (sec): 42.74 - samples/sec: 5073.88 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:27:58,496 epoch 5 - iter 654/1094 - loss 0.35325018 - time (sec): 50.69 - samples/sec: 5147.50 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:28:08,236 epoch 5 - iter 763/1094 - loss 0.35164840 - time (sec): 60.43 - samples/sec: 5039.41 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:28:15,481 epoch 5 - iter 872/1094 - loss 0.34996606 - time (sec): 67.68 - samples/sec: 5132.30 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:28:25,304 epoch 5 - iter 981/1094 - loss 0.34948040 - time (sec): 77.50 - samples/sec: 5046.10 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:28:32,718 epoch 5 - iter 1090/1094 - loss 0.34856077 - time (sec): 84.91 - samples/sec: 5111.92 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:28:32,984 ----------------------------------------------------------------------------------------------------
2023-11-16 09:28:32,986 EPOCH 5 done: loss 0.3486 - lr: 0.100000
2023-11-16 09:28:48,156 DEV : loss 0.19975405931472778 - f1-score (micro avg)  0.9399
2023-11-16 09:28:48,313  - 0 epochs without improvement
2023-11-16 09:28:48,314 saving best model
2023-11-16 09:28:48,327 ----------------------------------------------------------------------------------------------------
2023-11-16 09:28:55,902 epoch 6 - iter 109/1094 - loss 0.34820990 - time (sec): 7.57 - samples/sec: 5760.70 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:29:05,246 epoch 6 - iter 218/1094 - loss 0.34250507 - time (sec): 16.92 - samples/sec: 5126.20 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:29:12,694 epoch 6 - iter 327/1094 - loss 0.34224762 - time (sec): 24.36 - samples/sec: 5359.07 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:29:22,063 epoch 6 - iter 436/1094 - loss 0.34071287 - time (sec): 33.73 - samples/sec: 5140.17 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:29:29,044 epoch 6 - iter 545/1094 - loss 0.34059740 - time (sec): 40.71 - samples/sec: 5313.59 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:29:39,053 epoch 6 - iter 654/1094 - loss 0.34195318 - time (sec): 50.72 - samples/sec: 5130.45 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:29:46,391 epoch 6 - iter 763/1094 - loss 0.34169445 - time (sec): 58.06 - samples/sec: 5236.20 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:29:56,398 epoch 6 - iter 872/1094 - loss 0.34144661 - time (sec): 68.07 - samples/sec: 5105.27 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:30:04,813 epoch 6 - iter 981/1094 - loss 0.34066043 - time (sec): 76.48 - samples/sec: 5113.49 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:30:14,501 epoch 6 - iter 1090/1094 - loss 0.33980864 - time (sec): 86.17 - samples/sec: 5037.95 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:30:14,884 ----------------------------------------------------------------------------------------------------
2023-11-16 09:30:14,885 EPOCH 6 done: loss 0.3398 - lr: 0.100000
2023-11-16 09:30:31,549 DEV : loss 0.19904547929763794 - f1-score (micro avg)  0.9408
2023-11-16 09:30:31,812  - 0 epochs without improvement
2023-11-16 09:30:31,814 saving best model
2023-11-16 09:30:31,828 ----------------------------------------------------------------------------------------------------
2023-11-16 09:30:39,112 epoch 7 - iter 109/1094 - loss 0.33127178 - time (sec): 7.28 - samples/sec: 5871.15 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:30:47,748 epoch 7 - iter 218/1094 - loss 0.33657902 - time (sec): 15.92 - samples/sec: 5459.21 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:30:55,722 epoch 7 - iter 327/1094 - loss 0.33615405 - time (sec): 23.89 - samples/sec: 5418.61 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:31:03,950 epoch 7 - iter 436/1094 - loss 0.33694499 - time (sec): 32.12 - samples/sec: 5395.48 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:31:12,899 epoch 7 - iter 545/1094 - loss 0.33482176 - time (sec): 41.07 - samples/sec: 5257.96 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:31:20,528 epoch 7 - iter 654/1094 - loss 0.33468367 - time (sec): 48.70 - samples/sec: 5317.28 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:31:30,217 epoch 7 - iter 763/1094 - loss 0.33460434 - time (sec): 58.39 - samples/sec: 5194.25 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:31:37,682 epoch 7 - iter 872/1094 - loss 0.33376965 - time (sec): 65.85 - samples/sec: 5261.78 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:31:47,196 epoch 7 - iter 981/1094 - loss 0.33329764 - time (sec): 75.37 - samples/sec: 5181.48 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:31:55,121 epoch 7 - iter 1090/1094 - loss 0.33426499 - time (sec): 83.29 - samples/sec: 5214.03 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:31:55,423 ----------------------------------------------------------------------------------------------------
2023-11-16 09:31:55,426 EPOCH 7 done: loss 0.3342 - lr: 0.100000
2023-11-16 09:32:09,585 DEV : loss 0.19517748057842255 - f1-score (micro avg)  0.941
2023-11-16 09:32:09,743  - 0 epochs without improvement
2023-11-16 09:32:09,744 saving best model
2023-11-16 09:32:09,756 ----------------------------------------------------------------------------------------------------
2023-11-16 09:32:18,939 epoch 8 - iter 109/1094 - loss 0.32555982 - time (sec): 9.18 - samples/sec: 4626.27 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:32:26,673 epoch 8 - iter 218/1094 - loss 0.33085183 - time (sec): 16.91 - samples/sec: 5091.98 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:32:35,224 epoch 8 - iter 327/1094 - loss 0.32803467 - time (sec): 25.47 - samples/sec: 5085.33 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:32:45,147 epoch 8 - iter 436/1094 - loss 0.32905347 - time (sec): 35.39 - samples/sec: 4885.89 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:32:55,257 epoch 8 - iter 545/1094 - loss 0.32854627 - time (sec): 45.50 - samples/sec: 4759.38 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:33:02,723 epoch 8 - iter 654/1094 - loss 0.32881285 - time (sec): 52.96 - samples/sec: 4900.19 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:33:11,756 epoch 8 - iter 763/1094 - loss 0.33006718 - time (sec): 62.00 - samples/sec: 4879.87 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:33:20,646 epoch 8 - iter 872/1094 - loss 0.32978510 - time (sec): 70.89 - samples/sec: 4896.97 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:33:30,185 epoch 8 - iter 981/1094 - loss 0.32911586 - time (sec): 80.43 - samples/sec: 4861.21 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:33:38,023 epoch 8 - iter 1090/1094 - loss 0.32945046 - time (sec): 88.26 - samples/sec: 4919.81 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:33:38,249 ----------------------------------------------------------------------------------------------------
2023-11-16 09:33:38,251 EPOCH 8 done: loss 0.3295 - lr: 0.100000
2023-11-16 09:33:55,739 DEV : loss 0.19180220365524292 - f1-score (micro avg)  0.9416
2023-11-16 09:33:55,896  - 0 epochs without improvement
2023-11-16 09:33:55,898 saving best model
2023-11-16 09:33:55,908 ----------------------------------------------------------------------------------------------------
2023-11-16 09:34:04,398 epoch 9 - iter 109/1094 - loss 0.31988500 - time (sec): 8.49 - samples/sec: 5087.53 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:34:13,052 epoch 9 - iter 218/1094 - loss 0.32251950 - time (sec): 17.14 - samples/sec: 5028.37 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:34:21,403 epoch 9 - iter 327/1094 - loss 0.32382144 - time (sec): 25.49 - samples/sec: 5091.02 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:34:29,748 epoch 9 - iter 436/1094 - loss 0.32530121 - time (sec): 33.84 - samples/sec: 5109.07 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:34:37,171 epoch 9 - iter 545/1094 - loss 0.32506888 - time (sec): 41.26 - samples/sec: 5232.29 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:34:46,203 epoch 9 - iter 654/1094 - loss 0.32491287 - time (sec): 50.29 - samples/sec: 5153.82 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:34:54,012 epoch 9 - iter 763/1094 - loss 0.32549227 - time (sec): 58.10 - samples/sec: 5212.93 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:35:03,341 epoch 9 - iter 872/1094 - loss 0.32482160 - time (sec): 67.43 - samples/sec: 5142.05 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:35:11,015 epoch 9 - iter 981/1094 - loss 0.32441622 - time (sec): 75.10 - samples/sec: 5201.05 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:35:20,720 epoch 9 - iter 1090/1094 - loss 0.32522415 - time (sec): 84.81 - samples/sec: 5118.46 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:35:20,955 ----------------------------------------------------------------------------------------------------
2023-11-16 09:35:20,956 EPOCH 9 done: loss 0.3252 - lr: 0.100000
2023-11-16 09:35:34,515 DEV : loss 0.19097286462783813 - f1-score (micro avg)  0.9417
2023-11-16 09:35:34,781  - 0 epochs without improvement
2023-11-16 09:35:34,786 saving best model
2023-11-16 09:35:34,796 ----------------------------------------------------------------------------------------------------
2023-11-16 09:35:42,645 epoch 10 - iter 109/1094 - loss 0.32932808 - time (sec): 7.85 - samples/sec: 5478.52 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:35:51,809 epoch 10 - iter 218/1094 - loss 0.33152024 - time (sec): 17.01 - samples/sec: 5098.71 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:36:00,544 epoch 10 - iter 327/1094 - loss 0.32824419 - time (sec): 25.74 - samples/sec: 5088.37 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:36:09,149 epoch 10 - iter 436/1094 - loss 0.32806077 - time (sec): 34.35 - samples/sec: 5074.84 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:36:17,614 epoch 10 - iter 545/1094 - loss 0.32719729 - time (sec): 42.81 - samples/sec: 5096.76 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:36:25,447 epoch 10 - iter 654/1094 - loss 0.32451085 - time (sec): 50.65 - samples/sec: 5157.07 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:36:33,885 epoch 10 - iter 763/1094 - loss 0.32365173 - time (sec): 59.09 - samples/sec: 5142.35 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:36:41,088 epoch 10 - iter 872/1094 - loss 0.32312307 - time (sec): 66.29 - samples/sec: 5235.29 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:36:50,407 epoch 10 - iter 981/1094 - loss 0.32280534 - time (sec): 75.61 - samples/sec: 5164.86 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:36:57,591 epoch 10 - iter 1090/1094 - loss 0.32201557 - time (sec): 82.79 - samples/sec: 5243.56 - lr: 0.100000 - momentum: 0.000000
2023-11-16 09:36:57,835 ----------------------------------------------------------------------------------------------------
2023-11-16 09:36:57,837 EPOCH 10 done: loss 0.3221 - lr: 0.100000
2023-11-16 09:37:14,888 DEV : loss 0.19604137539863586 - f1-score (micro avg)  0.9418
2023-11-16 09:37:15,046  - 0 epochs without improvement
2023-11-16 09:37:15,048 saving best model
2023-11-16 09:37:15,064 ----------------------------------------------------------------------------------------------------
2023-11-16 09:37:15,066 Loading model from best epoch ...
2023-11-16 09:37:15,421 SequenceTagger predicts: Dictionary with 18 tags: part, n, ppm, v, punc, pron, conj, adj, adv, num, tn, fw, int, abb, sb, O, <START>, <STOP>
2023-11-16 09:37:27,968 
Results:
- F-score (micro) 0.9381
- F-score (macro) 0.8474
- Accuracy 0.9381

By class:
              precision    recall  f1-score   support

        part     0.9383    0.9477    0.9430     13207
           n     0.9157    0.9196    0.9176     10494
         ppm     0.9630    0.9875    0.9751      8638
           v     0.9364    0.9398    0.9381      7588
        punc     0.9958    0.9959    0.9958      5421
        pron     0.9600    0.9711    0.9655      2004
        conj     0.8836    0.9196    0.9012      1741
         adj     0.8172    0.7541    0.7843      1541
         adv     0.8883    0.7629    0.8209      1063
         num     0.9444    0.9413    0.9429       596
          tn     0.9463    0.9511    0.9487       593
          fw     0.8389    0.3463    0.4902       361
         int     0.8000    0.6471    0.7154        68
         abb     1.0000    0.5000    0.6667        38
          sb     0.8571    0.6000    0.7059        20

    accuracy                         0.9381     53373
   macro avg     0.9123    0.8123    0.8474     53373
weighted avg     0.9373    0.9381    0.9368     53373

2023-11-16 09:37:27,969 ----------------------------------------------------------------------------------------------------
