{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkIvWz9UTU8R",
        "outputId": "2e0c4e1e-b57d-4041-e1ab-59d7a37cb0c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flair\n",
            "  Downloading flair-0.13.0-py3-none-any.whl (387 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m387.2/387.2 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting boto3>=1.20.27 (from flair)\n",
            "  Downloading boto3-1.28.84-py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bpemb>=0.3.2 (from flair)\n",
            "  Downloading bpemb-0.3.4-py3-none-any.whl (19 kB)\n",
            "Collecting conllu>=4.0 (from flair)\n",
            "  Downloading conllu-4.5.3-py2.py3-none-any.whl (16 kB)\n",
            "Collecting deprecated>=1.2.13 (from flair)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting ftfy>=6.1.0 (from flair)\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gdown>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from flair) (4.6.6)\n",
            "Requirement already satisfied: gensim>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from flair) (4.3.2)\n",
            "Collecting huggingface-hub>=0.10.0 (from flair)\n",
            "  Downloading huggingface_hub-0.19.0-py3-none-any.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting janome>=0.4.2 (from flair)\n",
            "  Downloading Janome-0.5.0-py2.py3-none-any.whl (19.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langdetect>=1.0.9 (from flair)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: lxml>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from flair) (4.9.3)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.10/dist-packages (from flair) (3.7.1)\n",
            "Requirement already satisfied: more-itertools>=8.13.0 in /usr/local/lib/python3.10/dist-packages (from flair) (10.1.0)\n",
            "Collecting mpld3>=0.3 (from flair)\n",
            "  Downloading mpld3-0.5.9-py3-none-any.whl (201 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.2/201.2 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pptree>=3.1 (from flair)\n",
            "  Downloading pptree-3.1.tar.gz (3.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from flair) (2.8.2)\n",
            "Collecting pytorch-revgrad>=0.2.0 (from flair)\n",
            "  Downloading pytorch_revgrad-0.2.0-py3-none-any.whl (4.6 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from flair) (2023.6.3)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from flair) (1.2.2)\n",
            "Collecting segtok>=1.5.11 (from flair)\n",
            "  Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
            "Collecting sqlitedict>=2.0.0 (from flair)\n",
            "  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tabulate>=0.8.10 in /usr/local/lib/python3.10/dist-packages (from flair) (0.9.0)\n",
            "Requirement already satisfied: torch!=1.8,>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from flair) (2.1.0+cu118)\n",
            "Requirement already satisfied: tqdm>=4.63.0 in /usr/local/lib/python3.10/dist-packages (from flair) (4.66.1)\n",
            "Collecting transformer-smaller-training-vocab>=0.2.3 (from flair)\n",
            "  Downloading transformer_smaller_training_vocab-0.3.2-py3-none-any.whl (14 kB)\n",
            "Collecting transformers[sentencepiece]<5.0.0,>=4.18.0 (from flair)\n",
            "  Downloading transformers-4.35.0-py3-none-any.whl (7.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting urllib3<2.0.0,>=1.0.0 (from flair)\n",
            "  Downloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wikipedia-api>=0.5.7 (from flair)\n",
            "  Downloading Wikipedia_API-0.6.0-py3-none-any.whl (14 kB)\n",
            "Collecting semver<4.0.0,>=3.0.0 (from flair)\n",
            "  Downloading semver-3.0.2-py3-none-any.whl (17 kB)\n",
            "Collecting botocore<1.32.0,>=1.31.84 (from boto3>=1.20.27->flair)\n",
            "  Downloading botocore-1.31.84-py3-none-any.whl (11.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3>=1.20.27->flair)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.8.0,>=0.7.0 (from boto3>=1.20.27->flair)\n",
            "  Downloading s3transfer-0.7.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bpemb>=0.3.2->flair) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bpemb>=0.3.2->flair) (2.31.0)\n",
            "Collecting sentencepiece (from bpemb>=0.3.2->flair)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.13->flair) (1.14.1)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy>=6.1.0->flair) (0.2.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=4.4.0->flair) (3.13.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown>=4.4.0->flair) (1.16.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.4.0->flair) (4.11.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim>=4.2.0->flair) (1.11.3)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim>=4.2.0->flair) (6.4.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.0->flair) (2023.6.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.0->flair) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.0->flair) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.0->flair) (23.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (4.44.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (3.1.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mpld3>=0.3->flair) (3.1.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->flair) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->flair) (3.2.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.5.0->flair) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.5.0->flair) (3.2.1)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.5.0->flair) (2.1.0)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers[sentencepiece]<5.0.0,>=4.18.0->flair)\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers[sentencepiece]<5.0.0,>=4.18.0->flair)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]<5.0.0,>=4.18.0->flair) (3.20.3)\n",
            "Collecting huggingface-hub>=0.10.0 (from flair)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate>=0.20.3 (from transformers[sentencepiece]<5.0.0,>=4.18.0->flair)\n",
            "  Downloading accelerate-0.24.1-py3-none-any.whl (261 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.4/261.4 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.4.0->flair) (2.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mpld3>=0.3->flair) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bpemb>=0.3.2->flair) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bpemb>=0.3.2->flair) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bpemb>=0.3.2->flair) (2023.7.22)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests->bpemb>=0.3.2->flair) (1.7.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.8,>=1.5.0->flair) (1.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.3->transformers[sentencepiece]<5.0.0,>=4.18.0->flair) (5.9.5)\n",
            "Building wheels for collected packages: langdetect, pptree, sqlitedict\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993224 sha256=2fe4f43304a8bd9d7dd4562f96b1b7cab6e93add81d881db2caa4397948cbf3f\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "  Building wheel for pptree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pptree: filename=pptree-3.1-py3-none-any.whl size=4607 sha256=772dadd40dfe7742300c4fc3c1b8ac3a925425680931cc7935c7c3ccedf984c7\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/b6/0e/6f26eb9e6eb53ff2107a7888d72b5a6a597593956113037828\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16863 sha256=b03f0aa0c7704e55f0a7621b3cab708c1d3af66f6d1628e2619d5e671540f1ed\n",
            "  Stored in directory: /root/.cache/pip/wheels/79/d6/e7/304e0e6cb2221022c26d8161f7c23cd4f259a9e41e8bbcfabd\n",
            "Successfully built langdetect pptree sqlitedict\n",
            "Installing collected packages: sqlitedict, sentencepiece, pptree, janome, urllib3, semver, segtok, safetensors, langdetect, jmespath, ftfy, deprecated, conllu, botocore, wikipedia-api, s3transfer, pytorch-revgrad, mpld3, huggingface-hub, bpemb, tokenizers, boto3, accelerate, transformers, transformer-smaller-training-vocab, flair\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.7\n",
            "    Uninstalling urllib3-2.0.7:\n",
            "      Successfully uninstalled urllib3-2.0.7\n",
            "Successfully installed accelerate-0.24.1 boto3-1.28.84 botocore-1.31.84 bpemb-0.3.4 conllu-4.5.3 deprecated-1.2.14 flair-0.13.0 ftfy-6.1.1 huggingface-hub-0.17.3 janome-0.5.0 jmespath-1.0.1 langdetect-1.0.9 mpld3-0.5.9 pptree-3.1 pytorch-revgrad-0.2.0 s3transfer-0.7.0 safetensors-0.4.0 segtok-1.5.11 semver-3.0.2 sentencepiece-0.1.99 sqlitedict-2.1.0 tokenizers-0.14.1 transformer-smaller-training-vocab-0.3.2 transformers-4.35.0 urllib3-1.26.18 wikipedia-api-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install flair"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1XNMhPnz7o6V"
      },
      "outputs": [],
      "source": [
        "from flair.data import Sentence\n",
        "from flair.models import SequenceTagger\n",
        "from flair.trainers import ModelTrainer\n",
        "from flair.datasets import ColumnCorpus\n",
        "from flair.datasets import SentenceDataset\n",
        "from flair.data import Token\n",
        "from tqdm import tqdm\n",
        "import gensim\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "import multiprocessing\n",
        "from sklearn import utils\n",
        "import pandas as pd\n",
        "pd.set_option('max.colwidth', 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3RRk7LbTdFi",
        "outputId": "264bf08f-71bc-445e-d908-20e496d9b796"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "F8qiApLyTf0K"
      },
      "outputs": [],
      "source": [
        "!cp /content/drive/MyDrive/mypos-ver.3.0-flair.txt .\n",
        "!cp /content/drive/MyDrive/mypos-ver.3.0.txt ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AStNcyORVFAh"
      },
      "source": [
        "# Prepare Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7PuQenxUC5c",
        "outputId": "56a34025-6048-4ea0-bde7-d4055ab1173d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-11 08:54:55,923 Reading data from .\n",
            "2023-11-11 08:54:55,926 Train: mypos-ver.3.0-flair.txt\n",
            "2023-11-11 08:54:55,928 Dev: None\n",
            "2023-11-11 08:54:55,930 Test: None\n",
            "2023-11-11 08:55:11,079 No test split found. Using 0% (i.e. 4320 samples) of the train split as test data\n",
            "2023-11-11 08:55:11,113 No dev split found. Using 0% (i.e. 3888 samples) of the train split as dev data\n"
          ]
        }
      ],
      "source": [
        "dataset_file = \"mypos-ver.3.0-flair.txt\"\n",
        "\n",
        "# Define the columns in dataset\n",
        "columns = {0: 'text', 1: 'pos'}\n",
        "\n",
        "# Initialize the corpus\n",
        "corpus = ColumnCorpus(data_folder='.', column_format=columns, train_file=dataset_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sy2qWxXsVRbv"
      },
      "source": [
        "# Custom Embeddings (word2vec)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "J88eod_WOg-a"
      },
      "outputs": [],
      "source": [
        "df_wb = pd.read_csv(\"mypos-ver.3.0.txt\",encoding=\"utf-8\",names=[\"text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "mWSJd8dIPoeE",
        "outputId": "52da6f8c-842c-4864-ab6d-ecf46c8bca33"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                              text\n",
              "0  ဒီ ဆေး က ၁၀၀ ရာခိုင်နှုန်း ဆေးဘက်ဝင် အပင် များ မှ ဖော်စပ် ထား တာ ဖြစ် တယ် ။                                    \n",
              "1  အသစ် ဝယ် ထား တဲ့ ဆွယ်တာ က အသီး ထ နေ ပါ ပေါ့ ။                                                                  \n",
              "2  မ ကျန်းမာ လျှင် နတ်ဆရာ ထံ မေးမြန်း ၍ သက်ဆိုင်ရာ နတ် တို့ အား ပူဇော်ပသ ရ သည် ။                                  \n",
              "3  ပေဟိုင်ဥယျာဉ် ။                                                                                                \n",
              "4  နဝမ အိပ်မက် ကောသလမင်းအိပ်မက် ၉ နက်ရှိုင်း ကျယ်ဝန်း သော ရေကန် ကြီး တစ် ခု တွင် သတ္တဝါ တို့ ဆင်း ၍ ရေသောက် ကြ ၏ ။"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-476c5aba-8a65-42e3-a909-45b3d4d04bde\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ဒီ ဆေး က ၁၀၀ ရာခိုင်နှုန်း ဆေးဘက်ဝင် အပင် များ မှ ဖော်စပ် ထား တာ ဖြစ် တယ် ။</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>အသစ် ဝယ် ထား တဲ့ ဆွယ်တာ က အသီး ထ နေ ပါ ပေါ့ ။</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>မ ကျန်းမာ လျှင် နတ်ဆရာ ထံ မေးမြန်း ၍ သက်ဆိုင်ရာ နတ် တို့ အား ပူဇော်ပသ ရ သည် ။</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ပေဟိုင်ဥယျာဉ် ။</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>နဝမ အိပ်မက် ကောသလမင်းအိပ်မက် ၉ နက်ရှိုင်း ကျယ်ဝန်း သော ရေကန် ကြီး တစ် ခု တွင် သတ္တဝါ တို့ ဆင်း ၍ ရေသောက် ကြ ၏ ။</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-476c5aba-8a65-42e3-a909-45b3d4d04bde')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-476c5aba-8a65-42e3-a909-45b3d4d04bde button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-476c5aba-8a65-42e3-a909-45b3d4d04bde');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d9cf6e30-eb4d-4cd7-a7c0-54c99e2456ad\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d9cf6e30-eb4d-4cd7-a7c0-54c99e2456ad')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d9cf6e30-eb4d-4cd7-a7c0-54c99e2456ad button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df_wb.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "EHN8P3CqOmPz"
      },
      "outputs": [],
      "source": [
        "def tag_doc(df,label):\n",
        "    result = []\n",
        "    prefix = label\n",
        "    for i, t in zip(df.index, df):\n",
        "        result.append(TaggedDocument(t.split(), [prefix + '_%s' % i]))\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "z_8hyDq3OqAL"
      },
      "outputs": [],
      "source": [
        "tagged_docs = tag_doc(df_wb[\"text\"],\"doc\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHec0z_ROsKz",
        "outputId": "f54c7b1e-5602-4a5e-8f46-e410c4613047"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 43072/43072 [00:00<00:00, 378878.16it/s]\n"
          ]
        }
      ],
      "source": [
        "cores = multiprocessing.cpu_count()\n",
        "model_ug_cbow = Word2Vec(sg=0, vector_size=100, negative=5, window=5, workers=cores, alpha=0.065, min_alpha=0.001)\n",
        "model_ug_cbow.build_vocab([x.words for x in tqdm(tagged_docs)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0LRjJQfOuoD",
        "outputId": "f2b43d61-ee60-4a1e-a960-c649833e5e95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 43072/43072 [00:00<00:00, 285574.15it/s]\n",
            "100%|██████████| 43072/43072 [00:00<00:00, 2149962.65it/s]\n",
            "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n",
            "100%|██████████| 43072/43072 [00:00<00:00, 1922640.42it/s]\n",
            "100%|██████████| 43072/43072 [00:00<00:00, 2043031.03it/s]\n",
            "100%|██████████| 43072/43072 [00:00<00:00, 1990250.87it/s]\n",
            "100%|██████████| 43072/43072 [00:00<00:00, 2261464.13it/s]\n",
            "100%|██████████| 43072/43072 [00:00<00:00, 1957620.63it/s]\n",
            "100%|██████████| 43072/43072 [00:00<00:00, 2066021.61it/s]\n",
            "100%|██████████| 43072/43072 [00:00<00:00, 1827292.11it/s]\n",
            "100%|██████████| 43072/43072 [00:00<00:00, 1989768.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 9.65 s, sys: 56.6 ms, total: 9.71 s\n",
            "Wall time: 6.47 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "for epoch in range(10):\n",
        "    model_ug_cbow.train(utils.shuffle([x.words for x in tqdm(tagged_docs)]), total_examples=len(tagged_docs), epochs=1)\n",
        "    model_ug_cbow.alpha -= 0.004\n",
        "    model_ug_cbow.min_alpha = model_ug_cbow.alpha"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "1HPWpLmtOy5h"
      },
      "outputs": [],
      "source": [
        "model_ug_cbow.save(\"word2vec.model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "0tFeSY6bNSwT"
      },
      "outputs": [],
      "source": [
        "from flair.embeddings import TokenEmbeddings\n",
        "from gensim.models import Word2Vec\n",
        "from flair.data import Sentence\n",
        "from typing import List, Dict, Any\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "class CustomWordEmbeddings(TokenEmbeddings):\n",
        "    embeddings_name = \"custom_word_embeddings\"\n",
        "    def __init__(self, model_path):\n",
        "        super().__init__()\n",
        "        self.name = \"custom_word_embeddings\"\n",
        "        self.static_embeddings = True\n",
        "        self.model_path = model_path\n",
        "        self.model = Word2Vec.load(model_path)\n",
        "\n",
        "    @property\n",
        "    def embedding_length(self):\n",
        "        return self.model.vector_size\n",
        "\n",
        "    def embed(self, sentences: List[Sentence]) -> List[Sentence]:\n",
        "        for sentence in sentences:\n",
        "            for token in sentence.tokens:\n",
        "                if token.text in self.model.wv:\n",
        "                    embedding = np.array(self.model.wv[token.text])\n",
        "                    embedding_tensor = torch.tensor(embedding)  # Convert to a PyTorch tensor\n",
        "                    token.set_embedding(self.name, embedding_tensor)\n",
        "                else:\n",
        "                    # Handle out-of-vocabulary words\n",
        "                    token.set_embedding(self.name, torch.zeros(self.model.vector_size))\n",
        "        return sentences\n",
        "\n",
        "    @classmethod\n",
        "    def from_params(cls, params: Dict[str, Any]) -> \"CustomWordEmbeddings\":\n",
        "        model_path = params.get(\"model_path\")\n",
        "        return cls(model_path)\n",
        "\n",
        "    def to_params(self) -> Dict[str, Any]:\n",
        "        return {\"model_path\": self.model_path}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "epqudzHJR-Jy"
      },
      "outputs": [],
      "source": [
        "from flair.embeddings.base import EMBEDDING_CLASSES\n",
        "model_path = \"word2vec.model\"\n",
        "# Create a custom TokenEmbeddings object\n",
        "custom_word_embeddings = CustomWordEmbeddings(model_path)\n",
        "\n",
        "EMBEDDING_CLASSES.update({\n",
        "    \"custom_word_embeddings\": custom_word_embeddings\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jH13stmSX7Kr",
        "outputId": "384b036d-7ddd-4fdb-b6e3-3398d4e753b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token: ဟဲလို, Embedding: [ 0.3368485  -0.05676079  0.9369861   0.33802754 -0.31986502 -0.42675695\n",
            "  0.48137224 -0.15367013 -0.23659807 -0.36097813 -0.03043462  0.9305418\n",
            " -0.5686276   0.5049638   0.11482988 -0.2776011   0.6050444   0.30179742\n",
            "  0.21278134 -0.56342727 -0.2058191   0.12706596  0.76756513 -0.10850968\n",
            " -0.5881374  -0.04279719 -0.557096   -0.08774576  0.335045    0.14845648\n",
            "  0.31835693  0.33175445 -0.20714585 -0.25352716  0.09300841  0.19685848\n",
            " -0.38675672 -0.12135267 -0.06040484 -0.35751283  0.36362192 -0.3338699\n",
            "  0.49545383 -0.20312753  0.72002167 -0.40316752 -0.9428144  -0.0254768\n",
            "  0.7125956  -0.58786684 -0.45684573 -0.5788844   0.5501498  -0.18747619\n",
            " -0.30516037  0.13785106  0.04625937 -0.35307497  0.01141917 -0.39901528\n",
            "  0.7602262  -0.14059404  0.4028461   0.09337012  0.80735284  0.49872413\n",
            " -0.14325088 -0.44681272 -0.8533135   0.2440351  -0.5069529   0.05412304\n",
            " -0.05622599  0.09167283  0.64084214  0.09122819  0.02850553  0.42168605\n",
            "  0.2055734  -0.0514631  -0.3983614  -0.4690083  -0.6473181  -0.19200969\n",
            " -0.45565417 -0.4586609  -0.04991268 -0.08730104  0.16972779  0.53622496\n",
            "  0.4899487  -0.24001616 -0.47785267 -0.5258287   0.28972855  0.3943886\n",
            "  0.28527    -0.3539174  -0.59712505  0.23094174]\n",
            "Token: တင်းမ်, Embedding: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0.]\n",
            "Token: မင်္ဂလာ, Embedding: [ 0.43414637 -0.61671996 -0.36029804  0.31412604 -0.69902796  0.34223568\n",
            "  0.48054406  1.6268814  -1.5413082  -0.2434297   0.673588    1.9154296\n",
            " -0.10197649  1.415375    0.24493612  0.05251743  1.1614839   1.8043021\n",
            " -0.5121203  -1.1867163  -0.01072014  0.4695416   0.21342209 -0.622513\n",
            " -0.46136397  0.30673066 -0.8373899   1.5138687   0.8878796   0.08406622\n",
            "  0.9006156  -0.13452114  0.42433813 -1.3046956  -0.09887944 -0.5704193\n",
            " -1.5720934  -0.34091377  1.2109655  -0.53489166 -0.24680004 -1.6131619\n",
            "  0.7199434  -0.59686637  0.406769   -2.2066753  -0.8082955   0.21088329\n",
            "  1.9707992  -0.6353885  -0.13572942  0.5539619   1.3089805  -0.36108425\n",
            " -0.06330395  1.3309053   0.63925093 -0.5333356   1.3794926   0.01450824\n",
            "  0.80627686 -1.9817922   1.0720949   0.398196    2.4571333   1.5953193\n",
            "  0.49514383  0.12402755 -0.72682065 -0.3722854   0.4485663  -0.5231595\n",
            "  0.44534793  0.62633646  0.9745162   0.09972508  0.28488284  0.89683664\n",
            "  0.53860795 -0.2095794  -2.6974335   0.5167325  -0.261366    1.4320253\n",
            " -0.5917817  -0.7781372   0.6361991  -0.72921026  1.1129426  -0.00597867\n",
            "  0.9875172   1.560882   -0.85013014 -0.49345785 -1.4343276  -0.07086787\n",
            "  0.59935886  0.4317572  -1.0169046   2.4117074 ]\n",
            "Token: ပါ, Embedding: [ 0.17884949  1.2887028  -0.9424058  -0.10902946 -0.69644433 -0.518585\n",
            "  0.6597211  -0.70079625  0.08356805 -0.8318035   0.16345268 -0.27467135\n",
            " -0.90889436  0.07312407  0.7525439   0.8993514   0.10930929  0.3040744\n",
            " -0.67167157  0.02262866  0.35947365 -0.12744133  0.5644405  -0.01617731\n",
            " -0.8088144  -0.11223944 -0.13113886  0.34216508  0.15167561  0.16512647\n",
            "  0.12013318 -0.08752997  0.23652108 -0.2805604  -0.0524098   0.15210766\n",
            "  0.974939   -0.7683016  -0.5037082   0.61502045  0.12560555  0.1805534\n",
            " -0.22410877  0.41145018 -0.6372548   0.4132871   0.28613055 -0.33941254\n",
            "  0.94309044 -0.6631222   0.43040046  0.5974881  -0.8866236  -0.1864741\n",
            "  0.25305757  0.1150612  -0.10707444  0.48595306 -0.15705144 -0.9686148\n",
            "  0.5820942   0.32352874  0.32736725  0.28286442  0.78389144 -0.70908654\n",
            " -0.3948195  -0.9237917  -0.39009583  0.05849594 -0.05972436  0.8287752\n",
            " -0.6923143  -0.80057645  1.2269132  -0.25578496 -0.42075807  0.38402897\n",
            " -0.85840815 -0.35408148  0.04947237  0.6271669  -0.29417533  1.3395225\n",
            " -0.9374088   0.44391096 -0.06346855  0.92614585 -0.34568498 -0.09490728\n",
            " -0.33033177 -0.14335722  0.5308788   0.3493992   0.03861592  0.5014619\n",
            "  0.57285655 -0.27318797 -0.52308214 -0.59554684]\n",
            "Token: ဒီနေ့, Embedding: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0.]\n",
            "Token: မီတင်, Embedding: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0.]\n",
            "Token: ရှိ, Embedding: [ 0.58959097  0.83568037  0.36537516  1.1574775   0.5192672  -0.90070754\n",
            " -0.4581413   0.47177735  0.95958203 -1.4416317  -0.10956566  1.6941935\n",
            " -0.47684717  0.16639091 -0.25413793 -0.43059984  0.07290106 -1.1665976\n",
            " -2.4867194  -1.3235469  -0.97640705 -0.27656895  0.56349146 -0.9965154\n",
            " -0.02876333 -0.74128234 -1.1048433  -0.60455334  0.6129387   0.43334118\n",
            " -0.4637007  -1.0882561   0.33630452  0.06069355 -0.5864833   0.13128811\n",
            " -0.0837134  -0.20809779 -1.1761482  -0.6004518  -0.49501005  0.6800915\n",
            "  1.4021931  -1.0907598  -0.29770342 -1.2181859   1.4360081  -0.2288808\n",
            "  1.0527217   2.1277292   1.2636944  -0.7733806  -0.15588526  0.17823246\n",
            "  0.02679142 -0.7523313  -1.1793461  -0.13521233  0.90221256  0.55294317\n",
            " -0.8472967  -0.1264126  -0.4330552  -0.23669635 -0.21447287 -0.7805826\n",
            "  0.31287962  0.02753045 -1.0004177   0.5458085   0.35072303 -0.736996\n",
            "  0.8261818   1.6857957  -0.48737165  0.23861584 -0.23312062  0.84484285\n",
            " -0.81048167  0.3329237   0.46398193  1.5437866  -0.10316234 -0.6990082\n",
            "  1.8490008  -0.40017146 -0.3619868   0.31956354  0.68447447 -1.0211701\n",
            "  0.04114813 -0.3535113   0.10217687  0.47350213  0.91264874  0.80110043\n",
            " -0.04235921 -0.15553802 -0.06846227  0.35846937]\n",
            "Token: မယ်, Embedding: [ 0.32121605 -0.5716238   0.16888277 -0.7524521  -0.5955794  -1.0518706\n",
            "  0.46168497 -1.1552236  -0.61678416  1.2352631  -1.7071927  -0.6028058\n",
            " -1.8552405  -0.43309453  1.0134361   1.1706935   0.7878534   2.0355442\n",
            "  0.76293796 -0.26831326 -1.5753567   0.30775353 -0.3994483  -1.2562602\n",
            "  2.413897   -0.00850163  0.39693195 -0.59005475 -0.56050986 -0.8038721\n",
            "  1.7145258   0.48472103  0.67704    -1.1135216  -2.5807307   0.91709054\n",
            " -1.2854022  -0.74290067 -0.15585351 -0.41806722 -0.55998254  0.8310855\n",
            " -0.57884806  2.11806    -1.3281875   1.0912519   0.37683618  0.96963495\n",
            " -0.25780806 -0.77535796  0.3667258   0.7994778  -0.04016222  1.9582088\n",
            "  0.66917497  0.08362192  0.406419    1.9943334   0.35235858  0.7290894\n",
            "  1.4225823   1.1010432  -1.1412183   1.3239561   0.40112242 -0.29053077\n",
            " -1.0105045  -3.0006459   0.41665894  0.6191146   0.67280656 -0.36060563\n",
            "  0.41941485 -2.1451018   3.3639297   1.0202581  -1.0551829  -0.5352072\n",
            " -0.13654639  1.3773627  -0.11363147  0.6246108  -0.9940496   1.6498191\n",
            " -0.5960458   1.0475634  -1.9185811  -1.3342044  -0.21865073  0.78924495\n",
            " -1.0145826  -0.75754136  0.829796    1.1539124  -0.36868447 -1.2290977\n",
            "  0.56141174 -0.787077   -0.33016336  0.5264814 ]\n",
            "Token: နော်, Embedding: [ 1.6408653   0.4875752  -1.1667897  -0.83803236 -0.16595282 -1.1201406\n",
            "  1.0342436  -0.24658152 -0.5775926  -1.0002958   0.2804434  -1.7252554\n",
            "  0.2329564   1.8062075   0.61088985  0.02160936 -0.3336918   1.6474682\n",
            " -0.9018615   0.7305031  -1.4199145   0.8196828   0.11620743  1.0385942\n",
            " -0.25207415 -0.35783908  0.64431214  0.67045385  0.80101717 -0.27290747\n",
            "  0.5057167   0.17153929 -0.9721031  -0.4321814  -0.66745484 -0.27052182\n",
            "  1.3345804  -0.6437379  -0.5412037   0.52027994  0.45747495 -0.694428\n",
            " -0.15533978 -0.2343877   0.22683856  0.79232234 -0.77263117 -0.3045494\n",
            "  0.75125676 -1.1401714   0.82961875  2.0436938   0.8939181   0.9590394\n",
            " -0.49499577 -0.37033036  0.4410322   0.8499525   1.2076331   0.06611373\n",
            "  0.774529    0.29749057 -0.7441456   0.07363947 -0.2169772   0.45967156\n",
            "  0.19335876 -1.3639209   0.31428906  0.31929094 -0.7812377   0.30100653\n",
            " -0.2724435  -0.19840966  0.9795309   0.42451644 -0.05081138  0.44340056\n",
            " -0.43811494 -1.3855333  -1.1917552   0.11193319  0.12589867  2.131935\n",
            " -1.1298802   0.68319917 -0.45927864  0.69173574  0.09014139 -2.3876293\n",
            "  0.01140794  0.27472782  0.7226794   1.1869178   0.60654753 -1.165337\n",
            " -0.08655337 -1.9996998  -0.83834887 -0.22000402]\n"
          ]
        }
      ],
      "source": [
        "## test\n",
        "from flair.data import Sentence\n",
        "\n",
        "sentence1 = Sentence(\"ဟဲလို တင်းမ် မင်္ဂလာ ပါ\")\n",
        "sentence2 = Sentence(\"ဒီနေ့ မီတင် ရှိ မယ် နော်\")\n",
        "\n",
        "# Embed sentences using custom embedding\n",
        "sentences = [sentence1, sentence2]\n",
        "embedded_sentences = custom_word_embeddings.embed(sentences)\n",
        "\n",
        "# Print embedded vectors for tokens in each sentence\n",
        "for sentence in embedded_sentences:\n",
        "    for token in sentence.tokens:\n",
        "        print(f\"Token: {token.text}, Embedding: {token.get_embedding().numpy()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYolxd5CVgES"
      },
      "source": [
        "# Sequence Tagging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HcOqkOLDj3z",
        "outputId": "c927cccf-91a5-40ee-a92b-c67c15dc80d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-11 08:56:00,832 Computing label dictionary. Progress:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]\n",
            "34989it [00:01, 20409.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-11 08:56:02,567 Dictionary created for label 'pos' with 16 values: part (seen 108156 times), n (seen 84881 times), ppm (seen 70070 times), v (seen 62529 times), punc (seen 43869 times), pron (seen 16531 times), conj (seen 14349 times), adj (seen 12758 times), adv (seen 8708 times), num (seen 4807 times), tn (seen 4712 times), fw (seen 2517 times), int (seen 534 times), abb (seen 288 times), sb (seen 225 times), O (seen 1 times)\n",
            "2023-11-11 08:56:02,569 SequenceTagger predicts: Dictionary with 16 tags: part, n, ppm, v, punc, pron, conj, adj, adv, num, tn, fw, int, abb, sb, O\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-11 08:56:02,586 ----------------------------------------------------------------------------------------------------\n",
            "2023-11-11 08:56:02,590 Model: \"SequenceTagger(\n",
            "  (embeddings): CustomWordEmbeddings()\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=100, out_features=100, bias=True)\n",
            "  (rnn): LSTM(100, 256, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=18, bias=True)\n",
            "  (loss_function): ViterbiLoss()\n",
            "  (crf): CRF()\n",
            ")\"\n",
            "2023-11-11 08:56:02,593 ----------------------------------------------------------------------------------------------------\n",
            "2023-11-11 08:56:02,596 Corpus: 34989 train + 3888 dev + 4320 test sentences\n",
            "2023-11-11 08:56:02,599 ----------------------------------------------------------------------------------------------------\n",
            "2023-11-11 08:56:02,600 Train:  34989 sentences\n",
            "2023-11-11 08:56:02,604         (train_with_dev=False, train_with_test=False)\n",
            "2023-11-11 08:56:02,605 ----------------------------------------------------------------------------------------------------\n",
            "2023-11-11 08:56:02,607 Training Params:\n",
            "2023-11-11 08:56:02,614  - learning_rate: \"0.1\" \n",
            "2023-11-11 08:56:02,619  - mini_batch_size: \"32\"\n",
            "2023-11-11 08:56:02,620  - max_epochs: \"10\"\n",
            "2023-11-11 08:56:02,625  - shuffle: \"True\"\n",
            "2023-11-11 08:56:02,626 ----------------------------------------------------------------------------------------------------\n",
            "2023-11-11 08:56:02,627 Plugins:\n",
            "2023-11-11 08:56:02,629  - AnnealOnPlateau | patience: '3', anneal_factor: '0.5', min_learning_rate: '0.0001'\n",
            "2023-11-11 08:56:02,630 ----------------------------------------------------------------------------------------------------\n",
            "2023-11-11 08:56:02,631 Final evaluation on model from best epoch (best-model.pt)\n",
            "2023-11-11 08:56:02,632  - metric: \"('micro avg', 'f1-score')\"\n",
            "2023-11-11 08:56:02,634 ----------------------------------------------------------------------------------------------------\n",
            "2023-11-11 08:56:02,635 Computation:\n",
            "2023-11-11 08:56:02,636  - compute on device: cpu\n",
            "2023-11-11 08:56:02,637  - embedding storage: cpu\n",
            "2023-11-11 08:56:02,639 ----------------------------------------------------------------------------------------------------\n",
            "2023-11-11 08:56:02,640 Model training base path: \"pos_tagger\"\n",
            "2023-11-11 08:56:02,641 ----------------------------------------------------------------------------------------------------\n",
            "2023-11-11 08:56:02,642 ----------------------------------------------------------------------------------------------------\n",
            "2023-11-11 08:56:26,221 epoch 1 - iter 109/1094 - loss 1.16990756 - time (sec): 23.58 - samples/sec: 1852.20 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 08:56:47,544 epoch 1 - iter 218/1094 - loss 0.92953326 - time (sec): 44.90 - samples/sec: 1956.43 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 08:57:08,368 epoch 1 - iter 327/1094 - loss 0.82157808 - time (sec): 65.72 - samples/sec: 2000.65 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 08:57:39,935 epoch 1 - iter 436/1094 - loss 0.75678396 - time (sec): 97.29 - samples/sec: 1794.70 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 08:58:02,044 epoch 1 - iter 545/1094 - loss 0.71149865 - time (sec): 119.40 - samples/sec: 1825.46 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 08:58:23,263 epoch 1 - iter 654/1094 - loss 0.67983762 - time (sec): 140.62 - samples/sec: 1855.63 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 08:58:44,389 epoch 1 - iter 763/1094 - loss 0.65299367 - time (sec): 161.75 - samples/sec: 1883.30 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 08:59:05,114 epoch 1 - iter 872/1094 - loss 0.63163936 - time (sec): 182.47 - samples/sec: 1904.70 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 08:59:25,989 epoch 1 - iter 981/1094 - loss 0.61309894 - time (sec): 203.35 - samples/sec: 1920.50 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 08:59:47,565 epoch 1 - iter 1090/1094 - loss 0.59808752 - time (sec): 224.92 - samples/sec: 1928.36 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 08:59:48,210 ----------------------------------------------------------------------------------------------------\n",
            "2023-11-11 08:59:48,217 EPOCH 1 done: loss 0.5975 - lr: 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 61/61 [00:15<00:00,  3.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-11 09:00:04,030 DEV : loss 0.28407585620880127 - f1-score (micro avg)  0.9091\n",
            "2023-11-11 09:00:04,201  - 0 epochs without improvement\n",
            "2023-11-11 09:00:04,203 saving best model\n",
            "2023-11-11 09:00:04,215 ----------------------------------------------------------------------------------------------------\n",
            "2023-11-11 09:00:27,355 epoch 2 - iter 109/1094 - loss 0.46384721 - time (sec): 23.14 - samples/sec: 1910.73 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:00:50,942 epoch 2 - iter 218/1094 - loss 0.45374384 - time (sec): 46.73 - samples/sec: 1883.82 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:01:13,384 epoch 2 - iter 327/1094 - loss 0.44649715 - time (sec): 69.17 - samples/sec: 1896.75 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:01:41,400 epoch 2 - iter 436/1094 - loss 0.43959657 - time (sec): 97.18 - samples/sec: 1795.89 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:02:04,793 epoch 2 - iter 545/1094 - loss 0.43798278 - time (sec): 120.58 - samples/sec: 1805.63 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:02:26,082 epoch 2 - iter 654/1094 - loss 0.43534671 - time (sec): 141.87 - samples/sec: 1836.18 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:02:49,908 epoch 2 - iter 763/1094 - loss 0.43335522 - time (sec): 165.69 - samples/sec: 1837.42 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:03:12,520 epoch 2 - iter 872/1094 - loss 0.43153451 - time (sec): 188.30 - samples/sec: 1847.15 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:03:33,700 epoch 2 - iter 981/1094 - loss 0.42878869 - time (sec): 209.48 - samples/sec: 1865.49 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:03:54,265 epoch 2 - iter 1090/1094 - loss 0.42681627 - time (sec): 230.05 - samples/sec: 1884.71 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:03:54,819 ----------------------------------------------------------------------------------------------------\n",
            "2023-11-11 09:03:54,821 EPOCH 2 done: loss 0.4267 - lr: 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 61/61 [00:19<00:00,  3.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-11 09:04:14,804 DEV : loss 0.25052163004875183 - f1-score (micro avg)  0.9203\n",
            "2023-11-11 09:04:14,978  - 0 epochs without improvement\n",
            "2023-11-11 09:04:14,981 saving best model\n",
            "2023-11-11 09:04:14,991 ----------------------------------------------------------------------------------------------------\n",
            "2023-11-11 09:04:38,010 epoch 3 - iter 109/1094 - loss 0.40208020 - time (sec): 23.02 - samples/sec: 1915.70 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:05:03,014 epoch 3 - iter 218/1094 - loss 0.39851009 - time (sec): 48.02 - samples/sec: 1831.02 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:05:25,903 epoch 3 - iter 327/1094 - loss 0.39959716 - time (sec): 70.91 - samples/sec: 1849.70 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:05:53,588 epoch 3 - iter 436/1094 - loss 0.39864176 - time (sec): 98.59 - samples/sec: 1762.03 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:06:15,962 epoch 3 - iter 545/1094 - loss 0.39723863 - time (sec): 120.97 - samples/sec: 1792.49 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:06:37,896 epoch 3 - iter 654/1094 - loss 0.39489376 - time (sec): 142.90 - samples/sec: 1818.95 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:06:59,441 epoch 3 - iter 763/1094 - loss 0.39243627 - time (sec): 164.45 - samples/sec: 1839.52 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:07:22,606 epoch 3 - iter 872/1094 - loss 0.39259158 - time (sec): 187.61 - samples/sec: 1843.50 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:07:45,906 epoch 3 - iter 981/1094 - loss 0.39214908 - time (sec): 210.91 - samples/sec: 1847.93 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:08:09,466 epoch 3 - iter 1090/1094 - loss 0.39100498 - time (sec): 234.47 - samples/sec: 1849.28 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:08:10,018 ----------------------------------------------------------------------------------------------------\n",
            "2023-11-11 09:08:10,020 EPOCH 3 done: loss 0.3910 - lr: 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 61/61 [00:16<00:00,  3.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-11 09:08:26,990 DEV : loss 0.2347034513950348 - f1-score (micro avg)  0.9271\n",
            "2023-11-11 09:08:27,166  - 0 epochs without improvement\n",
            "2023-11-11 09:08:27,168 saving best model\n",
            "2023-11-11 09:08:27,180 ----------------------------------------------------------------------------------------------------\n",
            "2023-11-11 09:08:48,577 epoch 4 - iter 109/1094 - loss 0.37359806 - time (sec): 21.39 - samples/sec: 1981.45 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:09:10,343 epoch 4 - iter 218/1094 - loss 0.37383083 - time (sec): 43.16 - samples/sec: 1975.30 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:09:38,376 epoch 4 - iter 327/1094 - loss 0.37852034 - time (sec): 71.19 - samples/sec: 1814.23 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:10:01,825 epoch 4 - iter 436/1094 - loss 0.37663807 - time (sec): 94.64 - samples/sec: 1819.41 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:10:27,293 epoch 4 - iter 545/1094 - loss 0.37614075 - time (sec): 120.11 - samples/sec: 1807.13 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:10:49,069 epoch 4 - iter 654/1094 - loss 0.37670965 - time (sec): 141.89 - samples/sec: 1836.69 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:11:10,648 epoch 4 - iter 763/1094 - loss 0.37601372 - time (sec): 163.46 - samples/sec: 1853.73 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:11:32,569 epoch 4 - iter 872/1094 - loss 0.37545974 - time (sec): 185.39 - samples/sec: 1868.89 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:11:53,538 epoch 4 - iter 981/1094 - loss 0.37445299 - time (sec): 206.35 - samples/sec: 1888.25 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:12:19,680 epoch 4 - iter 1090/1094 - loss 0.37413499 - time (sec): 232.50 - samples/sec: 1865.13 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:12:20,286 ----------------------------------------------------------------------------------------------------\n",
            "2023-11-11 09:12:20,290 EPOCH 4 done: loss 0.3742 - lr: 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 61/61 [00:19<00:00,  3.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-11 09:12:40,192 DEV : loss 0.22643281519412994 - f1-score (micro avg)  0.9287\n",
            "2023-11-11 09:12:40,386  - 0 epochs without improvement\n",
            "2023-11-11 09:12:40,388 saving best model\n",
            "2023-11-11 09:12:40,398 ----------------------------------------------------------------------------------------------------\n",
            "2023-11-11 09:13:03,115 epoch 5 - iter 109/1094 - loss 0.37011375 - time (sec): 22.71 - samples/sec: 1938.11 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:13:28,766 epoch 5 - iter 218/1094 - loss 0.36725562 - time (sec): 48.36 - samples/sec: 1820.89 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:13:51,801 epoch 5 - iter 327/1094 - loss 0.36346235 - time (sec): 71.40 - samples/sec: 1833.89 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:14:15,901 epoch 5 - iter 436/1094 - loss 0.36575930 - time (sec): 95.50 - samples/sec: 1817.52 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:14:39,670 epoch 5 - iter 545/1094 - loss 0.36468513 - time (sec): 119.27 - samples/sec: 1816.90 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:15:01,274 epoch 5 - iter 654/1094 - loss 0.36391461 - time (sec): 140.87 - samples/sec: 1842.08 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:15:24,539 epoch 5 - iter 763/1094 - loss 0.36353138 - time (sec): 164.14 - samples/sec: 1846.71 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:15:45,970 epoch 5 - iter 872/1094 - loss 0.36352768 - time (sec): 185.57 - samples/sec: 1867.97 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:16:07,872 epoch 5 - iter 981/1094 - loss 0.36343954 - time (sec): 207.47 - samples/sec: 1877.09 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:16:31,183 epoch 5 - iter 1090/1094 - loss 0.36320067 - time (sec): 230.78 - samples/sec: 1877.69 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:16:33,150 ----------------------------------------------------------------------------------------------------\n",
            "2023-11-11 09:16:33,156 EPOCH 5 done: loss 0.3632 - lr: 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 61/61 [00:14<00:00,  4.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-11 09:16:48,897 DEV : loss 0.22073262929916382 - f1-score (micro avg)  0.9298\n",
            "2023-11-11 09:16:49,183  - 0 epochs without improvement\n",
            "2023-11-11 09:16:49,189 saving best model\n",
            "2023-11-11 09:16:49,204 ----------------------------------------------------------------------------------------------------\n",
            "2023-11-11 09:17:11,820 epoch 6 - iter 109/1094 - loss 0.35853802 - time (sec): 22.61 - samples/sec: 1885.17 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:17:34,603 epoch 6 - iter 218/1094 - loss 0.35555495 - time (sec): 45.39 - samples/sec: 1889.97 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:18:01,770 epoch 6 - iter 327/1094 - loss 0.35555282 - time (sec): 72.56 - samples/sec: 1786.98 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:18:23,828 epoch 6 - iter 436/1094 - loss 0.35623593 - time (sec): 94.62 - samples/sec: 1832.19 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:18:46,468 epoch 6 - iter 545/1094 - loss 0.35505121 - time (sec): 117.26 - samples/sec: 1845.22 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:19:08,633 epoch 6 - iter 654/1094 - loss 0.35492186 - time (sec): 139.42 - samples/sec: 1865.52 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:19:31,159 epoch 6 - iter 763/1094 - loss 0.35449087 - time (sec): 161.95 - samples/sec: 1875.21 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:19:53,951 epoch 6 - iter 872/1094 - loss 0.35429911 - time (sec): 184.74 - samples/sec: 1876.53 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:20:18,214 epoch 6 - iter 981/1094 - loss 0.35473737 - time (sec): 209.01 - samples/sec: 1866.91 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:20:41,048 epoch 6 - iter 1090/1094 - loss 0.35409112 - time (sec): 231.84 - samples/sec: 1870.36 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:20:41,972 ----------------------------------------------------------------------------------------------------\n",
            "2023-11-11 09:20:41,975 EPOCH 6 done: loss 0.3542 - lr: 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 61/61 [00:19<00:00,  3.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-11 09:21:02,631 DEV : loss 0.21526983380317688 - f1-score (micro avg)  0.9324\n",
            "2023-11-11 09:21:02,920  - 0 epochs without improvement\n",
            "2023-11-11 09:21:02,923 saving best model\n",
            "2023-11-11 09:21:02,943 ----------------------------------------------------------------------------------------------------\n",
            "2023-11-11 09:21:24,887 epoch 7 - iter 109/1094 - loss 0.33885506 - time (sec): 21.94 - samples/sec: 1957.26 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:21:47,281 epoch 7 - iter 218/1094 - loss 0.34639188 - time (sec): 44.34 - samples/sec: 1944.68 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:22:14,101 epoch 7 - iter 327/1094 - loss 0.34733535 - time (sec): 71.16 - samples/sec: 1810.00 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:22:37,568 epoch 7 - iter 436/1094 - loss 0.34416342 - time (sec): 94.62 - samples/sec: 1822.93 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:23:00,315 epoch 7 - iter 545/1094 - loss 0.34430062 - time (sec): 117.37 - samples/sec: 1844.55 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:23:23,177 epoch 7 - iter 654/1094 - loss 0.34582417 - time (sec): 140.23 - samples/sec: 1850.33 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:23:48,222 epoch 7 - iter 763/1094 - loss 0.34865834 - time (sec): 165.28 - samples/sec: 1837.75 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:24:09,760 epoch 7 - iter 872/1094 - loss 0.34796784 - time (sec): 186.81 - samples/sec: 1857.00 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:24:32,260 epoch 7 - iter 981/1094 - loss 0.34824013 - time (sec): 209.31 - samples/sec: 1864.00 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:24:55,813 epoch 7 - iter 1090/1094 - loss 0.34796282 - time (sec): 232.87 - samples/sec: 1861.80 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:24:56,825 ----------------------------------------------------------------------------------------------------\n",
            "2023-11-11 09:24:56,833 EPOCH 7 done: loss 0.3481 - lr: 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 61/61 [00:15<00:00,  4.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-11 09:25:12,810 DEV : loss 0.2150903195142746 - f1-score (micro avg)  0.9315\n",
            "2023-11-11 09:25:13,099  - 1 epochs without improvement\n",
            "2023-11-11 09:25:13,103 ----------------------------------------------------------------------------------------------------\n",
            "2023-11-11 09:25:36,646 epoch 8 - iter 109/1094 - loss 0.34173432 - time (sec): 23.54 - samples/sec: 1849.59 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:26:04,157 epoch 8 - iter 218/1094 - loss 0.34529662 - time (sec): 51.05 - samples/sec: 1710.05 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:26:28,944 epoch 8 - iter 327/1094 - loss 0.34806850 - time (sec): 75.84 - samples/sec: 1716.30 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:26:50,651 epoch 8 - iter 436/1094 - loss 0.34903566 - time (sec): 97.54 - samples/sec: 1772.81 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:27:14,615 epoch 8 - iter 545/1094 - loss 0.34745013 - time (sec): 121.51 - samples/sec: 1778.73 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:27:37,422 epoch 8 - iter 654/1094 - loss 0.34561540 - time (sec): 144.31 - samples/sec: 1801.12 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:27:58,588 epoch 8 - iter 763/1094 - loss 0.34379318 - time (sec): 165.48 - samples/sec: 1828.01 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:28:21,635 epoch 8 - iter 872/1094 - loss 0.34403605 - time (sec): 188.53 - samples/sec: 1839.22 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:28:44,243 epoch 8 - iter 981/1094 - loss 0.34437594 - time (sec): 211.13 - samples/sec: 1848.02 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:29:06,287 epoch 8 - iter 1090/1094 - loss 0.34374154 - time (sec): 233.18 - samples/sec: 1859.80 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:29:07,040 ----------------------------------------------------------------------------------------------------\n",
            "2023-11-11 09:29:07,045 EPOCH 8 done: loss 0.3437 - lr: 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 61/61 [00:20<00:00,  2.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-11 09:29:28,259 DEV : loss 0.2084665298461914 - f1-score (micro avg)  0.9355\n",
            "2023-11-11 09:29:28,543  - 0 epochs without improvement\n",
            "2023-11-11 09:29:28,549 saving best model\n",
            "2023-11-11 09:29:28,565 ----------------------------------------------------------------------------------------------------\n",
            "2023-11-11 09:29:50,563 epoch 9 - iter 109/1094 - loss 0.34076955 - time (sec): 21.99 - samples/sec: 1970.74 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:30:20,693 epoch 9 - iter 218/1094 - loss 0.34304226 - time (sec): 52.12 - samples/sec: 1681.09 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:30:44,662 epoch 9 - iter 327/1094 - loss 0.34393434 - time (sec): 76.09 - samples/sec: 1721.24 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:31:06,759 epoch 9 - iter 436/1094 - loss 0.34187769 - time (sec): 98.19 - samples/sec: 1772.96 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:31:31,407 epoch 9 - iter 545/1094 - loss 0.34257013 - time (sec): 122.84 - samples/sec: 1770.35 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:31:53,567 epoch 9 - iter 654/1094 - loss 0.34121324 - time (sec): 145.00 - samples/sec: 1796.27 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:32:15,630 epoch 9 - iter 763/1094 - loss 0.34049637 - time (sec): 167.06 - samples/sec: 1817.24 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:32:38,131 epoch 9 - iter 872/1094 - loss 0.33993946 - time (sec): 189.56 - samples/sec: 1831.28 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:33:00,329 epoch 9 - iter 981/1094 - loss 0.33886100 - time (sec): 211.76 - samples/sec: 1842.48 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:33:23,356 epoch 9 - iter 1090/1094 - loss 0.33930013 - time (sec): 234.79 - samples/sec: 1846.49 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:33:24,500 ----------------------------------------------------------------------------------------------------\n",
            "2023-11-11 09:33:24,501 EPOCH 9 done: loss 0.3394 - lr: 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 61/61 [00:15<00:00,  3.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-11 09:33:40,810 DEV : loss 0.20884999632835388 - f1-score (micro avg)  0.935\n",
            "2023-11-11 09:33:41,109  - 1 epochs without improvement\n",
            "2023-11-11 09:33:41,112 ----------------------------------------------------------------------------------------------------\n",
            "2023-11-11 09:34:05,176 epoch 10 - iter 109/1094 - loss 0.34376266 - time (sec): 24.06 - samples/sec: 1832.26 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:34:32,160 epoch 10 - iter 218/1094 - loss 0.34525073 - time (sec): 51.05 - samples/sec: 1723.89 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:34:58,294 epoch 10 - iter 327/1094 - loss 0.34544585 - time (sec): 77.18 - samples/sec: 1702.45 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:35:21,108 epoch 10 - iter 436/1094 - loss 0.34297990 - time (sec): 99.99 - samples/sec: 1742.73 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:35:43,655 epoch 10 - iter 545/1094 - loss 0.34202607 - time (sec): 122.54 - samples/sec: 1772.94 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:36:05,537 epoch 10 - iter 654/1094 - loss 0.34031077 - time (sec): 144.42 - samples/sec: 1801.82 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:36:27,211 epoch 10 - iter 763/1094 - loss 0.33903419 - time (sec): 166.10 - samples/sec: 1822.81 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:36:51,914 epoch 10 - iter 872/1094 - loss 0.33897969 - time (sec): 190.80 - samples/sec: 1817.89 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:37:15,366 epoch 10 - iter 981/1094 - loss 0.33764383 - time (sec): 214.25 - samples/sec: 1821.59 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:37:37,846 epoch 10 - iter 1090/1094 - loss 0.33698579 - time (sec): 236.73 - samples/sec: 1831.33 - lr: 0.100000 - momentum: 0.000000\n",
            "2023-11-11 09:37:38,527 ----------------------------------------------------------------------------------------------------\n",
            "2023-11-11 09:37:38,529 EPOCH 10 done: loss 0.3370 - lr: 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 61/61 [00:20<00:00,  3.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-11 09:37:59,228 DEV : loss 0.20708931982517242 - f1-score (micro avg)  0.9358\n",
            "2023-11-11 09:37:59,396  - 0 epochs without improvement\n",
            "2023-11-11 09:37:59,398 saving best model\n",
            "2023-11-11 09:37:59,415 ----------------------------------------------------------------------------------------------------\n",
            "2023-11-11 09:37:59,418 Loading model from best epoch ...\n",
            "2023-11-11 09:37:59,476 SequenceTagger predicts: Dictionary with 18 tags: part, n, ppm, v, punc, pron, conj, adj, adv, num, tn, fw, int, abb, sb, O, <START>, <STOP>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 68/68 [00:12<00:00,  5.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-11 09:38:13,249 \n",
            "Results:\n",
            "- F-score (micro) 0.9361\n",
            "- F-score (macro) 0.8363\n",
            "- Accuracy 0.9361\n",
            "\n",
            "By class:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        part     0.9632    0.9303    0.9465     13394\n",
            "           n     0.8705    0.9540    0.9103     10343\n",
            "         ppm     0.9705    0.9864    0.9784      8510\n",
            "           v     0.9387    0.9269    0.9328      7597\n",
            "        punc     0.9968    0.9981    0.9975      5357\n",
            "        pron     0.9644    0.9592    0.9618      2036\n",
            "        conj     0.8924    0.9323    0.9119      1744\n",
            "         adj     0.8390    0.7516    0.7929      1546\n",
            "         adv     0.8863    0.7032    0.7842      1031\n",
            "         num     0.8944    0.9202    0.9071       589\n",
            "          tn     0.9641    0.9164    0.9396       586\n",
            "          fw     0.7306    0.3422    0.4661       412\n",
            "         int     0.9091    0.8108    0.8571        74\n",
            "         abb     1.0000    0.3556    0.5246        45\n",
            "          sb     0.8667    0.5000    0.6341        26\n",
            "\n",
            "    accuracy                         0.9361     53290\n",
            "   macro avg     0.9124    0.7992    0.8363     53290\n",
            "weighted avg     0.9363    0.9361    0.9347     53290\n",
            "\n",
            "2023-11-11 09:38:13,251 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test_score': 0.9361231000187652}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "label_type = 'pos'\n",
        "\n",
        "# Create a label dictionary from the corpus\n",
        "label_dict = corpus.make_label_dictionary(label_type=label_type)\n",
        "\n",
        "# Create model\n",
        "model = SequenceTagger(hidden_size=256,\n",
        "                      embeddings=custom_word_embeddings,\n",
        "                      tag_dictionary=label_dict,\n",
        "                      tag_type=label_type)\n",
        "\n",
        "# Create the trainer and train the model\n",
        "trainer = ModelTrainer(model, corpus)\n",
        "trainer.train('pos_tagger', learning_rate=0.1, mini_batch_size=32, max_epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict"
      ],
      "metadata": {
        "id": "IeAE-YjhgaE5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the model you trained\n",
        "model = SequenceTagger.load('pos_tagger/final-model.pt')\n",
        "\n",
        "# create example sentence\n",
        "sentence = Sentence('မြန်မာနိုင်ငံ မှာ မောင်မောင် နဲ့ ကျွန်တော် ပဲ စာမေးပွဲ အောင် တာ ။')\n",
        "\n",
        "# predict tags and print\n",
        "model.predict(sentence)\n",
        "\n",
        "print(sentence.to_tagged_string())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfxgYDuAgTX5",
        "outputId": "9d93710a-74c6-4dfe-d70c-de6152b37be6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-11 09:38:21,977 SequenceTagger predicts: Dictionary with 18 tags: part, n, ppm, v, punc, pron, conj, adj, adv, num, tn, fw, int, abb, sb, O, <START>, <STOP>\n",
            "Sentence[10]: \"မြန်မာနိုင်ငံ မှာ မောင်မောင် နဲ့ ကျွန်တော် ပဲ စာမေးပွဲ အောင် တာ ။\" → [\"မြန်မာနိုင်ငံ\"/n, \"မှာ\"/ppm, \"မောင်မောင်\"/n, \"နဲ့\"/ppm, \"ကျွန်တော်\"/pron, \"ပဲ\"/part, \"စာမေးပွဲ\"/v, \"အောင်\"/part, \"တာ\"/part, \"။\"/punc]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create example sentence\n",
        "sentence = Sentence('ထို အစီအစဉ် မှာ တိုကျို တွင် အုပ်ချုပ်ရေး ဆိုင်ရာ ပညာရပ် များ ကို လေ့လာ နေ သော သခင်ထွန်းအုပ် အား ဟိုက်နန် တွင် စစ်ပညာ များ သင်ကြား နေ သည့် သခင်အောင်ဆန်း နှင့် တွေ့ဆုံ ၍ သခင်လူငယ် နှစ် ဖွဲ့ စည်းလုံးညီညွတ်ရေး ဆွေးနွေး ကြ ရန် ဖြစ် သည် ။')\n",
        "\n",
        "# predict tags and print\n",
        "model.predict(sentence)\n",
        "\n",
        "print(sentence.to_tagged_string())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6B23_hRyv5lo",
        "outputId": "71a13f8e-1226-4623-9182-bc1ef432d24d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence[36]: \"ထို အစီအစဉ် မှာ တိုကျို တွင် အုပ်ချုပ်ရေး ဆိုင်ရာ ပညာရပ် များ ကို လေ့လာ နေ သော သခင်ထွန်းအုပ် အား ဟိုက်နန် တွင် စစ်ပညာ များ သင်ကြား နေ သည့် သခင်အောင်ဆန်း နှင့် တွေ့ဆုံ ၍ သခင်လူငယ် နှစ် ဖွဲ့ စည်းလုံးညီညွတ်ရေး ဆွေးနွေး ကြ ရန် ဖြစ် သည် ။\" → [\"ထို\"/adj, \"အစီအစဉ်\"/n, \"မှာ\"/ppm, \"တိုကျို\"/n, \"တွင်\"/ppm, \"အုပ်ချုပ်ရေး\"/part, \"ဆိုင်ရာ\"/n, \"ပညာရပ်\"/n, \"များ\"/part, \"ကို\"/ppm, \"လေ့လာ\"/v, \"နေ\"/part, \"သော\"/part, \"သခင်ထွန်းအုပ်\"/n, \"အား\"/ppm, \"ဟိုက်နန်\"/n, \"တွင်\"/ppm, \"စစ်ပညာ\"/n, \"များ\"/part, \"သင်ကြား\"/v, \"နေ\"/part, \"သည့်\"/part, \"သခင်အောင်ဆန်း\"/n, \"နှင့်\"/ppm, \"တွေ့ဆုံ\"/v, \"၍\"/conj, \"သခင်လူငယ်\"/n, \"နှစ်\"/tn, \"ဖွဲ့\"/v, \"စည်းလုံးညီညွတ်ရေး\"/part, \"ဆွေးနွေး\"/v, \"ကြ\"/part, \"ရန်\"/conj, \"ဖြစ်\"/v, \"သည်\"/ppm, \"။\"/punc]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}